{"_id":{"$id":"51feb421560e7051629da862"},"date":"2010-02-27 13:37:29","content":"Back from phpuk2010 and feeling like I really want to contribute to some open source projects! I'll summarize the main points I took away from each of the talks I attended.\r\n\r\n<strong>Josh Holmes - Keynote talk - The Lost Art of Simplicity:<\/strong>\r\n\r\nJosh talked about how overcomplicating things seems to happen all to often and grave a great example of a man simply trying to pluck an apple from a tree. He introduced me to \"the truck factor\" which I knew by a different name but this one has a much better ing to it :)\r\n\r\n<strong>Stefan Priebsch - AntiPHPatterns:<\/strong>\r\n\r\nI took alot away from this talk. Stefan had some great usage cases where singletons are bad and I have come across similar problems in my own code. I still think are cases where it makes sense and they are great for chucking an example together, but for production code and unit testing they are a bit of a nightmare.\r\n\r\nHe also pointed out that using global within a class is a real pain for unit testing too and ideally you should use the class __construct() function to get any required arrays\/objects from outside the class (dependencies).\r\n\r\ncakePHP took a bit of bashing during the talk due to it's insanely high number of globals. CakePHP wasn't alone either it seems a great many open source PHP projects are taking steps to fix there high use of globals and singletons.\r\n\r\n<strong>Remo Biagioni - Database Optimization:<\/strong>\r\n\r\nThis was a story about how a small side projected grew into a multi server nightmare in just a few short years. He gave some good examples of how not to manage your databases and some equelly good examples of how to speed up different aspects of the database server. In short:\r\n<ol>\r\n\t<li>Reduce the number of queries as much as possible by merging them together.<\/li>\r\n\t<li>INSERT IGNORES are faster than a SELECT query and then a possible a INSERT query.<\/li>\r\n\t<li>Move the queue to memory<\/li>\r\n\t<li>Use LOW_PRIORITY on DELETEs that don't matter.<\/li>\r\n\t<li>memcached is awesome, if your not using memcached or something like it then you really should.<\/li>\r\n\t<li>If possible, avoid; LIKE, GROUP BY, DISTINCT as these are all slow.<\/li>\r\n\t<li>Use something like beanstalked to manage the queue.<\/li>\r\n\t<li>They used an MD5 hash (calculated in php) as a primary\/unique row key. This is faster than using AUTO_INCREMENT to manage the primary keys. Note: you could use sha1() for even less chance of a duplicate key.<\/li>\r\n<\/ol>\r\nHA Proxy, Google's\u00a0 MMM, NoSQL and CouchDB all got a mention near the end and during question time.\r\n\r\n<strong>Kore Nordmann - CouchDB &amp; PHPillow:<\/strong>\r\n\r\nThis talk introduced a completely new concept to me and got me excited about a new kind of database. CouchDB is different, very different to relational databases such a MySQL. Firstly it uses http to connect to it! This opens up immediate possibilities and new security concerns but means you can make a database connection within javascript in the users browser! There is no schema in CouchDB as the \"rows\" are infact JSON objects. This means each row doesn't have to follow any kind of set rules, they could have a different number of \"columns\" or have very different data in each \"column\" such as a another object or multi dimensional array. Your probably thinking the same thing I was at this point, \"do we have indexes in CouchDB? and how the hell would they work\". Well, there are indexes in CouchDB and they are very flexible, but they are harder to implemenet than in say MySQL. Indexes in CouchDB are called <a href=\"http:\/\/wiki.apache.org\/couchdb\/Introduction_to_CouchDB_views\">views<\/a>. These views exist as code that is run to create e.g. a btree index. The great part is, you write the code for the view! and you can write it in javascript (or other languages with the help of plugins). This gives you far more direct control of your indexes and should result in you having a far better understanding of your databases internal workings. PHPillow is the framework for implementing coucheDB within PHP.\r\n\r\n<strong>Juliette Folmer - Regex-fu:<\/strong>\r\n\r\nAlthough there's not alot to blog about from the regex talk, you really had to be there... Two things I did pick up was that PCRE is faster than POSIX and the php documentation for it is here <a href=\"http:\/\/php.net\/manual\/en\/book.pcre.php\">http:\/\/php.net\/manual\/en\/book.pcre.php<\/a>. Also the built in and blindingly fast PHP Filter extension is often forgotten or not known about and the documentation is here <a href=\"http:\/\/www.php.net\/manual\/en\/intro.filter.php\">http:\/\/www.php.net\/manual\/en\/intro.filter.php<\/a>.\r\n\r\n<strong>Damien Seguy - PHP Code Audits:<\/strong>\r\n\r\nDamien gave a good talk on security in PHP, he covered the usual stuff about REGISTER_GLOBALS being a terrible idea on any system, production or development. But went into far more detail on how he searches for security issues in a short space of time so that you can quickly audit your own code. The bottom line is search the php code with the help of a tokenizer for php injection in places that use backticks require\/include etc and eval. Search the codes notes for swearing and keywords such as \"todo\".\r\n\r\nA good tip for finding redundent code he gave was search for variables that only appear once. Some of these will be global variables but some of them may well lead you to old or troubling code.\r\n\r\nTools he recommended were Groogle, Reviewboard, Rietvold and Smartbear.","title":"phpuk2010","status":"publish","name":"phpuk2010","type":"","tags":["PHP","phpuk2010","MySQL","CoucheDB","phpuk"],"categories":["General\/Techie","Code"],"comments":[]}